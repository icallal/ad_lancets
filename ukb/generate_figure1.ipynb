{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf338a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score, mean_squared_error, log_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Colorblind-friendly palette (Okabe-Ito)\n",
    "CB_PALETTE = [\n",
    "    \"#000000\",  # black\n",
    "    \"#E69F00\",  # orange\n",
    "    \"#499BCA\",  # sky blue\n",
    "    \"#009E73\",  # bluish green\n",
    "    \"#F0E442\",  # yellow\n",
    "    \"#0072B2\",  # blue\n",
    "    \"#D55E00\",  # vermillion\n",
    "    \"#CC79A7\",  # reddish purple\n",
    "]\n",
    "\n",
    "rename = {\n",
    "    \"4700-0.0\": 'Age Cataract Diagnosed',\n",
    "    \"5901-0.0\": 'Age Diabetic Retinopathy Diagnosed',\n",
    "    \"30780-0.0\": 'LDL',\n",
    "    \"head_injury\": 'Head Injury',\n",
    "    \"22038-0.0\": 'Min/Week Moderate Activity',\n",
    "    \"20161-0.0\": 'Years of Smoking',\n",
    "    \"alcohol_consumption\": 'Alcohol consumption',\n",
    "    \"hypertension\": 'Hypertension',\n",
    "    \"obesity\": 'Obesity',\n",
    "    \"diabetes\": 'Diabetes',\n",
    "    \"hearing_loss\": 'Hearing Loss',\n",
    "    \"depression\": 'Depression',\n",
    "    \"freq_friends_family_visit\": 'Frequency of Friends/Family Visits',\n",
    "    \"24012-0.0\": 'Distance to Major Road',\n",
    "    \"24018-0.0\": 'NO2 Air Pollution',\n",
    "    \"24019-0.0\": 'PM10 Air Pollution',\n",
    "    \"24006-0.0\": 'PM2.5 Air Pollution',\n",
    "    \"24015-0.0\": 'Amount of Major Roads',\n",
    "    \"24011-0.0\": 'Traffic Intensity',\n",
    "    '6138-0.0': 'Education Level',\n",
    "    '845-0.0': 'Years Education',\n",
    "    'curr_age': 'Age',  # changed from 'Current Age' to 'Age'\n",
    "    \"NIFK9/BIN1 (hg38)\": \"BIN1 (hg38)\",  # clarify this mapping as needed\n",
    "}\n",
    "\n",
    "def feature_importances_plot(path_to_experiment, ax=None, color=CB_PALETTE[1]):\n",
    "    df = pd.read_csv(os.path.join(path_to_experiment, 'summary_stats/features.txt'))\n",
    "    df['fnames'] = df['fnames'].replace(rename)\n",
    "    df = df.sort_values(by='avg_fi', ascending=False)\n",
    "    df = df.head(20)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, len(df) * 0.3))\n",
    "    ax.barh(df['fnames'], df['avg_fi'], color=color, capsize=4, xerr=df['std_fi'])\n",
    "    ax.set_xlabel('Average Feature Importance', fontsize=22, fontweight='bold')\n",
    "    ax.set_ylabel('Features', fontsize=22, fontweight='bold')\n",
    "    ax.tick_params(axis='x', labelsize=16, length=8)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    ax.set_title('', fontsize=0)\n",
    "    ax.invert_yaxis()\n",
    "    return df[['fnames', 'avg_fi', 'std_fi']] #'std_fi\n",
    "\n",
    "def mean_roc_curve(true_labels_list, predicted_probs_list):\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    auc_l = []\n",
    "    auc_maxfpr025_l = []\n",
    "    for true_labels, predicted_probs in zip(true_labels_list, predicted_probs_list):\n",
    "        rocauc = roc_auc_score(true_labels, predicted_probs)\n",
    "        auc_l.append(rocauc)\n",
    "        rocauc_maxfpr025 = roc_auc_score(true_labels, predicted_probs, max_fpr=0.25)\n",
    "        auc_maxfpr025_l.append(rocauc_maxfpr025)\n",
    "        fpr, tpr, _ = roc_curve(true_labels, predicted_probs)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(auc_l)\n",
    "    mean_auc_maxfpr025 = np.mean(auc_maxfpr025_l)\n",
    "    std_auc_maxfpr025 = np.std(auc_maxfpr025_l)\n",
    "    return mean_fpr, mean_tpr, std_tpr, mean_auc, std_auc, mean_auc_maxfpr025, std_auc_maxfpr025\n",
    "\n",
    "def extract_true_pred(exp):\n",
    "    pred = \"test_labels_predictions.parquet\"\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for folder in os.listdir(exp):\n",
    "        folder_path = os.path.join(exp, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, pred)\n",
    "            if os.path.isfile(file_path):\n",
    "                df = pd.read_parquet(file_path, engine='fastparquet')\n",
    "                predictions_df = df.y_pred\n",
    "                trues_df = df.y_test\n",
    "                preds.append(predictions_df)\n",
    "                trues.append(trues_df)\n",
    "    return preds, trues\n",
    "\n",
    "experiments = [\n",
    "    './results/LDE_only',\n",
    "    './results_all/age_alone/none/allages/AD/lgbm',\n",
    "    './results_all/all_demographics/apoe/allages/AD/lgbm',\n",
    "    './results_all/all_demographics/LDE/allages/AD/lgbm',\n",
    "    './results_all/demographics_lancet2024/none/allages/AD/lgbm',\n",
    "    './results_all/demographics_lancet2024/apoe/allages/AD/lgbm',\n",
    "    './results_all/demographics_lancet2024/LDE/allages/AD/lgbm'\n",
    "]\n",
    "\n",
    "name_map = {\n",
    "    'LDE_only': 'Genetics alone',\n",
    "    'age_alone': 'Age alone',\n",
    "    'all_demographics': 'All demographics',\n",
    "    'demographics_lancet2024': 'Demographics + lancet factors',\n",
    "}\n",
    "\n",
    "genes_map = {\n",
    "    'apoe': 'APOE',\n",
    "    'LDE': 'All SNPs',\n",
    "}\n",
    "\n",
    "def plot_roc_curve(experiments, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    for i, exp_path in enumerate(experiments):\n",
    "        preds, trues = extract_true_pred(exp_path)\n",
    "        (mean_fpr, mean_tpr, std_tpr, mean_auc, std_auc, _, _) = mean_roc_curve(trues, preds)\n",
    "        color = CB_PALETTE[i % len(CB_PALETTE)]\n",
    "        parts = exp_path.split('/')\n",
    "        main_key = parts[2] if len(parts) > 2 else exp_path\n",
    "        title = name_map.get(main_key, main_key)\n",
    "        if len(parts) > 3 and parts[3] != 'none':\n",
    "            gene_key = parts[3]\n",
    "            gene_label = genes_map.get(gene_key, gene_key)\n",
    "            title += f\" ({gene_label})\"\n",
    "        label = f\"{title}\\nAUC: {mean_auc:.3f} ± {std_auc:.3f}\"\n",
    "        ax.plot(mean_fpr, mean_tpr, color=color, label=label, lw=3, alpha=0.9)\n",
    "        tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(mean_fpr, tpr_lower, tpr_upper, color=color, alpha=0.15)\n",
    "    ax.legend(loc='lower right', fontsize=18)\n",
    "    ax.set_xlabel(\"False Positive Rate\", fontsize=22, fontweight='bold')\n",
    "    ax.set_ylabel(\"True Positive Rate\", fontsize=22, fontweight='bold')\n",
    "    ax.tick_params(axis='both', labelsize=18, length=8)\n",
    "    ax.set_title('', fontsize=0)\n",
    "    return ax\n",
    "\n",
    "def mean_pr_curve(true_labels_list, predicted_probs_list):\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions = []\n",
    "    ap_scores = []\n",
    "    for true_labels, predicted_probs in zip(true_labels_list, predicted_probs_list):\n",
    "        ap = average_precision_score(true_labels, predicted_probs)\n",
    "        ap_scores.append(ap)\n",
    "        precision, recall, _ = precision_recall_curve(true_labels, predicted_probs)\n",
    "        interp_precision = np.interp(mean_recall[::-1], recall[::-1], precision[::-1])[::-1]\n",
    "        precisions.append(interp_precision)\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    std_precision = np.std(precisions, axis=0)\n",
    "    mean_ap = np.mean(ap_scores)\n",
    "    std_ap = np.std(ap_scores)\n",
    "    return mean_precision, std_precision, mean_recall, mean_ap, std_ap\n",
    "\n",
    "def plot_multiple_pr_curves(experiments, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    for i, exp_path in enumerate(experiments):\n",
    "        preds, trues = extract_true_pred(exp_path)\n",
    "        if len(preds) == 0 or len(trues) == 0:\n",
    "            continue\n",
    "        mean_precision, std_precision, mean_recall, mean_ap, std_ap = mean_pr_curve(trues, preds)\n",
    "        parts = exp_path.split('/')\n",
    "        main_key = parts[2] if len(parts) > 2 else exp_path\n",
    "        title = name_map.get(main_key, main_key)\n",
    "        if len(parts) > 3 and parts[3] != 'none':\n",
    "            gene_key = parts[3]\n",
    "            gene_label = genes_map.get(gene_key, gene_key)\n",
    "            title += f\" ({gene_label})\"\n",
    "        color = CB_PALETTE[i % len(CB_PALETTE)]\n",
    "        label = f\"{title}\\nAP: {mean_ap:.3f} ± {std_ap:.3f}\"\n",
    "        ax.plot(mean_recall, mean_precision, color=color, label=label, lw=3, alpha=0.9)\n",
    "        ax.fill_between(mean_recall,\n",
    "                        np.maximum(mean_precision - std_precision, 0),\n",
    "                        np.minimum(mean_precision + std_precision, 1),\n",
    "                        color=color, alpha=0.15)\n",
    "    ax.set_xlabel('Recall', fontsize=22, fontweight='bold')\n",
    "    ax.set_ylabel('Precision', fontsize=22, fontweight='bold')\n",
    "    ax.tick_params(axis='both', labelsize=18, length=8)\n",
    "    ax.set_xlim([-0.05, 1.0])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.set_title('', fontsize=0)\n",
    "    ax.grid(False)\n",
    "    return ax\n",
    "\n",
    "def plot_multiple_calibration_curves(experiments, ax=None):\n",
    "    \"\"\"\n",
    "    Plot multiple calibration curves for different experiments with log scale and enhanced metrics.\n",
    "    If ax is provided, plot on that axis (for panel use); otherwise, create a new figure.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import mean_squared_error, log_loss\n",
    "    from sklearn.calibration import calibration_curve\n",
    "\n",
    "    colors = CB_PALETTE\n",
    "    created_fig = False\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        created_fig = True\n",
    "\n",
    "    ax.set_xlabel(\"Mean Predicted Probability\", fontsize=22, fontweight='bold')\n",
    "    ax.set_ylabel(\"Fraction of Positives\", fontsize=22, fontweight='bold')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.tick_params(axis='both', labelsize=18, length=8)\n",
    "\n",
    "    pred_l = []\n",
    "    true_l = []\n",
    "\n",
    "    for i, exp_path in enumerate(experiments):\n",
    "        try:\n",
    "            preds, trues = extract_true_pred(exp_path)\n",
    "            if len(preds) == 0 or len(trues) == 0:\n",
    "                continue\n",
    "            all_preds = np.concatenate(preds)\n",
    "            all_trues = np.concatenate(trues)\n",
    "\n",
    "            # Calculate calibration curve with quantile strategy\n",
    "            prob_true, prob_pred = calibration_curve(all_trues, all_preds, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "            # Remove zero values to avoid log(0) issues\n",
    "            non_zero_indices = (prob_true > 0) & (prob_pred > 0)\n",
    "            prob_true = prob_true[non_zero_indices]\n",
    "            prob_pred = prob_pred[non_zero_indices]\n",
    "\n",
    "            pred_l.extend(prob_pred)\n",
    "            true_l.extend(prob_true)\n",
    "\n",
    "            # Extract experiment title\n",
    "            parts = exp_path.split('/')\n",
    "            main_key = parts[2] if len(parts) > 2 else exp_path\n",
    "            title = name_map.get(main_key, main_key)\n",
    "            if len(parts) > 3 and parts[3] != 'none':\n",
    "                gene_key = parts[3]\n",
    "                gene_label = genes_map.get(gene_key, gene_key)\n",
    "                title += f\" ({gene_label})\"\n",
    "\n",
    "            # Calculate additional metrics\n",
    "            mse = mean_squared_error(all_trues, all_preds)\n",
    "            ll = log_loss(all_trues, all_preds)\n",
    "\n",
    "            color = colors[i % len(colors)]\n",
    "            label = f\"{title}\\nMSE: {mse:.3f}, LL: {ll:.3f}\"\n",
    "\n",
    "            ax.plot(prob_pred, prob_true,\n",
    "                    color=color,\n",
    "                    marker='s',\n",
    "                    label=label,\n",
    "                    lw=2,\n",
    "                    markersize=6)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {exp_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Add diagonal reference line\n",
    "    if pred_l and true_l:\n",
    "        min_val = min(min(pred_l), min(true_l)) * 0.9\n",
    "        max_val = max(max(pred_l), max(true_l)) * 1.1\n",
    "        ax.plot([min_val, max_val], [min_val, max_val],\n",
    "                linestyle='--', color='gray', alpha=0.8, label='Perfect Calibration')\n",
    "        ax.set_xlim(min_val, max_val)\n",
    "        ax.set_ylim(min_val, max_val)\n",
    "\n",
    "    ax.legend(loc='upper left', fontsize=8, frameon=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_title('', fontsize=0)\n",
    "\n",
    "    if created_fig:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_conf_mtx(path, ax=None):\n",
    "    metrics = pd.read_csv(f'{path}/summary_stats/metrics.txt', header=None).T\n",
    "    metrics.columns = metrics.iloc[0]\n",
    "    metrics = metrics.drop(0).reset_index(drop=True)\n",
    "    for val in ['TN', 'FP', 'FN', 'TP']:\n",
    "        metrics[val] = pd.to_numeric(metrics[val], errors='coerce')\n",
    "    array = {val: metrics[val].mean() for val in ['TN', 'FP', 'FN', 'TP']}\n",
    "    conf_matrix = np.array([[array['TP'], array['FP']],\n",
    "                            [array['FN'], array['TN']]])\n",
    "    total = conf_matrix.sum()\n",
    "    percent_matrix = conf_matrix / total * 100\n",
    "    labels = np.array([\n",
    "        [f\"TP\\n{conf_matrix[0,0]:.0f}\\n({percent_matrix[0,0]:.1f}%)\", \n",
    "         f\"FP\\n{conf_matrix[0,1]:.0f}\\n({percent_matrix[0,1]:.1f}%)\"],\n",
    "        [f\"FN\\n{conf_matrix[1,0]:.0f}\\n({percent_matrix[1,0]:.1f}%)\", \n",
    "         f\"TN\\n{conf_matrix[1,1]:.0f}\\n({percent_matrix[1,1]:.1f}%)\"]\n",
    "    ])\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix, annot=labels, fmt='', cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=['', ''], yticklabels=['', ''], square=True, linewidths=0.5, ax=ax)\n",
    "    ax.set_xlabel('Predicted Values', fontsize=22, fontweight='bold')\n",
    "    ax.set_ylabel('Actual Values', fontsize=22, fontweight='bold')\n",
    "    ax.set_title('', fontsize=0)\n",
    "    ax.tick_params(axis='both', labelsize=22, length=8)\n",
    "    for text in ax.texts:\n",
    "        text.set_fontsize(24)\n",
    "        text.set_fontweight('bold')\n",
    "    return ax\n",
    "\n",
    "\n",
    "# --- AGGREGATE PANELS INTO ONE FIGURE ---\n",
    "\n",
    "def publication_figure(experiments, conf_matrix_path, feature_imp_path, output_png='publication_figure.png'):\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    font = fm.FontProperties(weight='bold')\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(24, 14))\n",
    "    gs = gridspec.GridSpec(2, 3, width_ratios=[1.2, 1, 1], height_ratios=[1, 1.1], figure=fig)\n",
    "\n",
    "    # ROC panel\n",
    "    ax_roc = fig.add_subplot(gs[0, 0])\n",
    "    plot_roc_curve(experiments, ax=ax_roc)\n",
    "    ax_roc.set_title('A', loc='left', fontsize=28, fontweight='bold', pad=20)\n",
    "    ax_roc.legend(loc='lower right', fontsize=9, frameon=True, prop=font)\n",
    "    # PRC panel\n",
    "    ax_prc = fig.add_subplot(gs[0, 1])\n",
    "    plot_multiple_pr_curves(experiments, ax=ax_prc)\n",
    "    ax_prc.set_title('B', loc='left', fontsize=28, fontweight='bold', pad=20)\n",
    "    ax_prc.legend(loc='upper right', fontsize=9, frameon=True, prop=font)\n",
    "\n",
    "    # Confusion matrix panel\n",
    "    ax_conf = fig.add_subplot(gs[0, 2])\n",
    "    generate_conf_mtx(conf_matrix_path, ax=ax_conf)\n",
    "    ax_conf.set_title('C', loc='left', fontsize=28, fontweight='bold', pad=20)\n",
    "\n",
    "    # Calibration panel\n",
    "    ax_cal = fig.add_subplot(gs[1, 0])\n",
    "    plot_multiple_calibration_curves(experiments, ax=ax_cal)\n",
    "    ax_cal.set_title('D', loc='left', fontsize=28, fontweight='bold', pad=20)\n",
    "    ax_cal.legend(loc='upper left', fontsize=9, frameon=True, prop=font)\n",
    "\n",
    "    # Bold tick marks for A, B, and C panels\n",
    "    for axis in [ax_roc, ax_prc, ax_cal]:\n",
    "        axis.tick_params(axis='both', labelsize=18, length=8, width=2)\n",
    "        for tick in axis.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for tick in axis.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontweight('bold')\n",
    "\n",
    "\n",
    "    # Feature importance panel (span both columns 1 and 2 in row 1)\n",
    "    ax_fi = fig.add_subplot(gs[1, 1:])\n",
    "    feature_importances_plot(feature_imp_path, ax=ax_fi, color=\"#009E73\")\n",
    "    ax_fi.set_title('E', loc='left', fontsize=28, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.savefig(output_png, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage:\n",
    "publication_figure(\n",
    "    experiments,\n",
    "    conf_matrix_path='./results_all/demographics_lancet2024/LDE/allages/AD/lgbm',  # or any experiment folder with metrics.txt\n",
    "    feature_imp_path='./results_all/demographics_lancet2024/LDE/allages/AD/lgbm',  # or any experiment folder with features.txt\n",
    "    output_png='publication_figure.png'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lowpyAD)",
   "language": "python",
   "name": "lowpyad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
