{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83eba1e2-7ce0-4b62-b606-884fa216ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from mlutils import calc_results\n",
    "from mlutils import pick_threshold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "experiment_paths = [\"./flaml_results\"]\n",
    "\n",
    "\n",
    "def normalize_importances(importance_array):\n",
    "    \"\"\"\n",
    "    Normalize feature importances to sum to 1 (convert to percentages)\n",
    "    \"\"\"\n",
    "    # Ensure we don't divide by zero\n",
    "    total = np.sum(importance_array)\n",
    "    if total == 0:\n",
    "        return np.zeros_like(importance_array)\n",
    "    return importance_array / total\n",
    "\n",
    "\n",
    "def get_top_features(automl):\n",
    "    \"\"\"\n",
    "    Extracts the top features from an AutoML model.\n",
    "    Parameters:\n",
    "    automl (object): The AutoML model object.\n",
    "    Returns:\n",
    "    list: A list of the top features from the AutoML model.\n",
    "    \"\"\"\n",
    "    if len(automl.feature_importances_) == 1:\n",
    "        feature_names = np.array(automl.feature_names_in_)[\n",
    "            np.argsort(abs(automl.feature_importances_[0]))[::-1]\n",
    "        ]\n",
    "        fi = automl.feature_importances_[0][\n",
    "            np.argsort(abs(automl.feature_importances_[0]))[::-1]\n",
    "        ]\n",
    "    else:\n",
    "        feature_names = np.array(automl.feature_names_in_)[\n",
    "            np.argsort(abs(automl.feature_importances_))[::-1]\n",
    "        ]\n",
    "        fi = automl.feature_importances_[\n",
    "            np.argsort(abs(automl.feature_importances_))[::-1]\n",
    "        ]\n",
    "\n",
    "    return feature_names, fi\n",
    "\n",
    "def evaluate_results(root):\n",
    "    summary = {} \n",
    "    features = {}\n",
    "    for num in os.listdir(root): \n",
    "        if num in [\"0\", \"1\", \"2\", \"3\", \"4\"]:\n",
    "            full = os.path.join(root, num)\n",
    "            if os.path.isdir(full): \n",
    "                train = pd.read_parquet(os.path.join(full, \"train_labels_predictions.parquet\"), engine = 'fastparquet')\n",
    "                test = pd.read_parquet(os.path.join(full, \"test_labels_predictions.parquet\"), engine = 'fastparquet')\n",
    "\n",
    "                threshold = pick_threshold(train['y_train'], train['y_pred'])\n",
    "            \n",
    "                test_results = calc_results(test['y_test'], test['y_pred'], threshold = threshold)\n",
    "            \n",
    "                summary[num] = test_results\n",
    "\n",
    "                model = joblib.load(os.path.join(full, \"flaml_best_model.joblib\"))\n",
    "\n",
    "                if isinstance(model, LogisticRegression):\n",
    "                    # For Logistic Regression, we need to handle coefficients\n",
    "                    fi = model.coef_[0]\n",
    "                    fnames = model.feature_names_in_\n",
    "                elif isinstance(model, LGBMClassifier):\n",
    "                    # For LGBMClassifier, we can use feature importances directly\n",
    "                    fi = model.feature_importances_\n",
    "                    fnames = model.feature_name_\n",
    "\n",
    "                fi = normalize_importances(fi)\n",
    "                # Create DataFrame\n",
    "                df = pd.DataFrame({\n",
    "                    'fi': fi,\n",
    "                    'fnames': fnames\n",
    "                })\n",
    "\n",
    "                features[num] = df\n",
    "    \n",
    "    return summary, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708fe7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0': auroc          0.702427\n",
       "  avg_prec       0.183266\n",
       "  threshold      0.140298\n",
       "  TP            16.000000\n",
       "  TN           258.000000\n",
       "  FP            79.000000\n",
       "  FN            23.000000\n",
       "  accuracy       0.728723\n",
       "  bal_acc        0.587918\n",
       "  prec_n         0.918149\n",
       "  prec_p         0.168421\n",
       "  recall_n       0.765579\n",
       "  recall_p       0.410256\n",
       "  f1_n           0.834951\n",
       "  f1_p           0.238806\n",
       "  mcc            0.123378\n",
       "  dtype: float64,\n",
       "  '1': auroc          0.793883\n",
       "  avg_prec       0.260849\n",
       "  threshold      0.132745\n",
       "  TP            31.000000\n",
       "  TN           239.000000\n",
       "  FP            98.000000\n",
       "  FN             8.000000\n",
       "  accuracy       0.718085\n",
       "  bal_acc        0.752035\n",
       "  prec_n         0.967611\n",
       "  prec_p         0.240310\n",
       "  recall_n       0.709199\n",
       "  recall_p       0.794872\n",
       "  f1_n           0.818493\n",
       "  f1_p           0.369048\n",
       "  mcc            0.323739\n",
       "  dtype: float64,\n",
       "  '2': auroc          0.742677\n",
       "  avg_prec       0.282454\n",
       "  threshold      0.132425\n",
       "  TP            20.000000\n",
       "  TN           255.000000\n",
       "  FP            82.000000\n",
       "  FN            19.000000\n",
       "  accuracy       0.731383\n",
       "  bal_acc        0.634749\n",
       "  prec_n         0.930657\n",
       "  prec_p         0.196078\n",
       "  recall_n       0.756677\n",
       "  recall_p       0.512821\n",
       "  f1_n           0.834697\n",
       "  f1_p           0.283688\n",
       "  mcc            0.184810\n",
       "  dtype: float64,\n",
       "  '3': auroc          0.788927\n",
       "  avg_prec       0.232256\n",
       "  threshold      0.125159\n",
       "  TP            30.000000\n",
       "  TN           232.000000\n",
       "  FP           105.000000\n",
       "  FN             8.000000\n",
       "  accuracy       0.698667\n",
       "  bal_acc        0.738950\n",
       "  prec_n         0.966667\n",
       "  prec_p         0.222222\n",
       "  recall_n       0.688427\n",
       "  recall_p       0.789474\n",
       "  f1_n           0.804159\n",
       "  f1_p           0.346821\n",
       "  mcc            0.300450\n",
       "  dtype: float64,\n",
       "  '4': auroc          0.700297\n",
       "  avg_prec       0.191523\n",
       "  threshold      0.149024\n",
       "  TP            18.000000\n",
       "  TN           255.000000\n",
       "  FP            82.000000\n",
       "  FN            20.000000\n",
       "  accuracy       0.728000\n",
       "  bal_acc        0.615180\n",
       "  prec_n         0.927273\n",
       "  prec_p         0.180000\n",
       "  recall_n       0.756677\n",
       "  recall_p       0.473684\n",
       "  f1_n           0.833333\n",
       "  f1_p           0.260870\n",
       "  mcc            0.157199\n",
       "  dtype: float64},\n",
       " {'0':           fi          fnames\n",
       "  0   0.013158         GDTOTAL\n",
       "  1   0.000000       MH14BALCH\n",
       "  2   0.171053       MH16BSMOK\n",
       "  3   0.118421             AGE\n",
       "  4   0.000000        PTGENDER\n",
       "  5   0.184211        PTEDUCAT\n",
       "  6   0.039474        HMHYPERT\n",
       "  7   0.118421  CLINICAL_LDL_C\n",
       "  8   0.197368             bmi\n",
       "  9   0.000000        apoe_2/2\n",
       "  10  0.026316        apoe_2/3\n",
       "  11  0.000000        apoe_2/4\n",
       "  12  0.052632        apoe_3/3\n",
       "  13  0.026316        apoe_3/4\n",
       "  14  0.052632        apoe_4/4,\n",
       "  '1':          fi          fnames\n",
       "  0   0.01250         GDTOTAL\n",
       "  1   0.00000       MH14BALCH\n",
       "  2   0.22500       MH16BSMOK\n",
       "  3   0.13125             AGE\n",
       "  4   0.00000        PTGENDER\n",
       "  5   0.17500        PTEDUCAT\n",
       "  6   0.00625        HMHYPERT\n",
       "  7   0.13750  CLINICAL_LDL_C\n",
       "  8   0.13750             bmi\n",
       "  9   0.00000        apoe_2/2\n",
       "  10  0.04375        apoe_2/3\n",
       "  11  0.00000        apoe_2/4\n",
       "  12  0.06250        apoe_3/3\n",
       "  13  0.02500        apoe_3/4\n",
       "  14  0.04375        apoe_4/4,\n",
       "  '2':           fi          fnames\n",
       "  0   0.052916         GDTOTAL\n",
       "  1   0.007559       MH14BALCH\n",
       "  2   0.124730       MH16BSMOK\n",
       "  3   0.168467             AGE\n",
       "  4   0.003780        PTGENDER\n",
       "  5   0.133369        PTEDUCAT\n",
       "  6   0.011339        HMHYPERT\n",
       "  7   0.205724  CLINICAL_LDL_C\n",
       "  8   0.140929             bmi\n",
       "  9   0.000000        apoe_2/2\n",
       "  10  0.040497        apoe_2/3\n",
       "  11  0.002160        apoe_2/4\n",
       "  12  0.049136        apoe_3/3\n",
       "  13  0.018898        apoe_3/4\n",
       "  14  0.040497        apoe_4/4,\n",
       "  '3':           fi          fnames\n",
       "  0   0.026882         GDTOTAL\n",
       "  1   0.000000       MH14BALCH\n",
       "  2   0.188172       MH16BSMOK\n",
       "  3   0.139785             AGE\n",
       "  4   0.000000        PTGENDER\n",
       "  5   0.096774        PTEDUCAT\n",
       "  6   0.037634        HMHYPERT\n",
       "  7   0.193548  CLINICAL_LDL_C\n",
       "  8   0.134409             bmi\n",
       "  9   0.000000        apoe_2/2\n",
       "  10  0.069892        apoe_2/3\n",
       "  11  0.000000        apoe_2/4\n",
       "  12  0.069892        apoe_3/3\n",
       "  13  0.005376        apoe_3/4\n",
       "  14  0.037634        apoe_4/4,\n",
       "  '4':           fi          fnames\n",
       "  0   0.018018         GDTOTAL\n",
       "  1   0.004505       MH14BALCH\n",
       "  2   0.144144       MH16BSMOK\n",
       "  3   0.162162             AGE\n",
       "  4   0.004505        PTGENDER\n",
       "  5   0.121622        PTEDUCAT\n",
       "  6   0.004505        HMHYPERT\n",
       "  7   0.184685  CLINICAL_LDL_C\n",
       "  8   0.202703             bmi\n",
       "  9   0.000000        apoe_2/2\n",
       "  10  0.058559        apoe_2/3\n",
       "  11  0.000000        apoe_2/4\n",
       "  12  0.054054        apoe_3/3\n",
       "  13  0.009009        apoe_3/4\n",
       "  14  0.031532        apoe_4/4})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_results(experiment_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f8cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fi_avg(merged_df):\n",
    "    \"\"\"\n",
    "    Calculate the average feature importance across all folds and drop individual fold columns.\n",
    "    \"\"\"\n",
    "    # Identify columns that start with 'fi_' and calculate their mean\n",
    "    fi_cols = [col for col in merged_df.columns if col.startswith('fi_')]\n",
    "    merged_df['avg_fi'] = merged_df[fi_cols].mean(axis=1, skipna=True)\n",
    "    merged_df = merged_df.drop(columns=fi_cols)\n",
    "    \n",
    "    # some cleaning\n",
    "    sorted_features = merged_df.sort_values(by='avg_fi', ascending=False)\n",
    "    # only split at \"_\" if the name starts with \"rs\"\n",
    "    sorted_features['fnames'] = sorted_features['fnames'].apply(\n",
    "        lambda x: x.split(\"_\")[0] if isinstance(x, str) and x.startswith(\"rs\") else x\n",
    "    )\n",
    "    sorted_features['fnames'] = sorted_features['fnames'].astype('string')\n",
    "\n",
    "    return sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24bcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def summarize_stats(metrics1, metrics2): \n",
    "    path1 = os.path.join(metrics1, \"summary_stats/metrics.txt\")\n",
    "    path2 = os.path.join(metrics2, \"summary_stats/metrics.txt\")\n",
    "\n",
    "    df_metrics1 = pd.read_csv(path1)\n",
    "    df_metrics2 = pd.read_csv(path2)\n",
    "\n",
    "    merged_df = df_metrics1.merge(df_metrics2, on='Unnamed: 0').round(3)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def summarize_features(features1, features2):\n",
    "    path1 = os.path.join(features1, \"summary_stats/features.txt\")\n",
    "    path2 = os.path.join(features2, \"summary_stats/features.txt\")\n",
    "\n",
    "    df_features1 = pd.read_csv(path1)\n",
    "    df_features2 = pd.read_csv(path2)\n",
    "\n",
    "    df_features1 = df_features1.drop_duplicates(subset=['fnames'])\n",
    "    df_features2 = df_features2.drop_duplicates(subset=['fnames'])\n",
    "\n",
    "    merged_features = pd.concat([df_features1, df_features2], axis = 1)\n",
    "\n",
    "    return merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f7956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_summary(sorted_features, path): \n",
    "    # grab snp names and add\n",
    "    ad_genes = pd.read_csv('../../raw_data/MONDO_0004975_associations_export (1).tsv', sep = \"\\t\")\n",
    "\n",
    "    snps = ad_genes[['riskAllele', 'mappedGenes', 'pValue', 'beta', 'locations']]\n",
    "    snps['snp'] = snps['riskAllele'].str.split(\"-\").str[0]\n",
    "    snps = snps.drop(columns='riskAllele')\n",
    "\n",
    "    # separate non_snp features\n",
    "    \n",
    "    non_snp_feats = sorted_features[~sorted_features['fnames'].str.startswith(\"rs\")]\n",
    "    # filter by genes only present in fnames, then add to fnames\n",
    "    snps = snps[snps['snp'].isin(sorted_features['fnames'])]\n",
    "    sorted_features = sorted_features.merge(snps, right_on = 'snp', left_on = 'fnames')\n",
    "    sorted_features = sorted_features.drop_duplicates(subset=['fnames'])\n",
    "\n",
    "    # add non-snp features back to sorted_features\n",
    "    sorted_features = pd.concat([sorted_features, non_snp_feats])\n",
    "    sorted_features = sorted_features.sort_values(by='avg_fi', ascending=False)\n",
    "\n",
    "    # Create the summary_stats directory if it doesn't exist\n",
    "    summary_stats_dir = os.path.join(path, \"summary_stats\")\n",
    "    os.makedirs(summary_stats_dir, exist_ok=True)\n",
    "\n",
    "    #print(sorted_features.head(10))\n",
    "    sorted_features.to_csv(f'{summary_stats_dir}/features.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7fc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics_summary(summary, path):\n",
    "    # Convert summary dictionary to DataFrame\n",
    "    df_summary = pd.DataFrame(summary)\n",
    "    \n",
    "    # Save the summary DataFrame to a CSV file\n",
    "    summary_stats_dir = os.path.join(path, \"summary_stats\")\n",
    "    os.makedirs(summary_stats_dir, exist_ok=True)\n",
    "\n",
    "    #print(df_summary.head())\n",
    "    df_summary.to_csv(f'{summary_stats_dir}/metrics.txt', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4746f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ./flaml_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3291026/68647937.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  snps['snp'] = snps['riskAllele'].str.split(\"-\").str[0]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    summary = None\n",
    "    features = None\n",
    "    \n",
    "    '''\n",
    "    path = './results_all_exp/age_sex_lancet2024/all_snps/65up/AD/lgbm'\n",
    "    summary, features = evaluate_results(path)\n",
    "\n",
    "    # merge data from 5 folds together\n",
    "    merged_df = None\n",
    "      \n",
    "    for fold_name, df in features.items():\n",
    "        # rename\n",
    "        df_renamed = df.rename(columns={'fi': f'fi_{fold_name}'})\n",
    "\n",
    "        if merged_df is None:\n",
    "            merged_df = df_renamed\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, df_renamed, on='fnames', how='outer')\n",
    "\n",
    "    sorted_features = calculate_fi_avg(merged_df)\n",
    "\n",
    "    generate_feature_summary(sorted_features, path)\n",
    "    generate_metrics_summary(summary, path)\n",
    "\n",
    "    '''\n",
    "    for path in experiment_paths:\n",
    "        print(f\"Evaluating {path}\")\n",
    "        summary, features = evaluate_results(path)\n",
    "\n",
    "        # merge data from 5 folds together\n",
    "        merged_df = None\n",
    "        for fold_name, df in features.items():\n",
    "            df_renamed = df.rename(columns={'fi': f'fi_{fold_name}'})\n",
    "            if merged_df is None:\n",
    "                merged_df = df_renamed\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df_renamed, on='fnames', how='outer')\n",
    "\n",
    "        sorted_features = calculate_fi_avg(merged_df)\n",
    "\n",
    "        generate_feature_summary(sorted_features, path)\n",
    "        generate_metrics_summary(summary, path)\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd900df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3291026/68647937.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  snps['snp'] = snps['riskAllele'].str.split(\"-\").str[0]\n"
     ]
    }
   ],
   "source": [
    "path = './flaml_results'\n",
    "summary, features = evaluate_results(path)\n",
    "\n",
    "# merge data from 5 folds together\n",
    "merged_df = None\n",
    "for fold_name, df in features.items():\n",
    "    df_renamed = df.rename(columns={'fi': f'fi_{fold_name}'})\n",
    "    if merged_df is None:\n",
    "        merged_df = df_renamed\n",
    "    else:\n",
    "        merged_df = pd.merge(merged_df, df_renamed, on='fnames', how='outer')\n",
    "\n",
    "sorted_features = calculate_fi_avg(merged_df)\n",
    "\n",
    "generate_feature_summary(sorted_features, path)\n",
    "generate_metrics_summary(summary, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd8d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUROC for flaml_results: 0.7455999999999999, sd 0.045313353440238825\n",
      "Average AUROC for flaml_results: 0.7455999999999999, sd 0.045313353440238825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnames</th>\n",
       "      <th>avg_fi</th>\n",
       "      <th>mappedGenes</th>\n",
       "      <th>pValue</th>\n",
       "      <th>beta</th>\n",
       "      <th>locations</th>\n",
       "      <th>snp</th>\n",
       "      <th>fnames</th>\n",
       "      <th>avg_fi</th>\n",
       "      <th>mappedGenes</th>\n",
       "      <th>pValue</th>\n",
       "      <th>beta</th>\n",
       "      <th>locations</th>\n",
       "      <th>snp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MH16BSMOK</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MH16BSMOK</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLINICAL_LDL_C</td>\n",
       "      <td>0.167976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLINICAL_LDL_C</td>\n",
       "      <td>0.167976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmi</td>\n",
       "      <td>0.162582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bmi</td>\n",
       "      <td>0.162582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PTEDUCAT</td>\n",
       "      <td>0.142195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PTEDUCAT</td>\n",
       "      <td>0.142195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apoe_3/3</td>\n",
       "      <td>0.057643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apoe_3/3</td>\n",
       "      <td>0.057643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apoe_2/3</td>\n",
       "      <td>0.047803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apoe_2/3</td>\n",
       "      <td>0.047803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apoe_4/4</td>\n",
       "      <td>0.041209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apoe_4/4</td>\n",
       "      <td>0.041209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GDTOTAL</td>\n",
       "      <td>0.024695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GDTOTAL</td>\n",
       "      <td>0.024695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HMHYPERT</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HMHYPERT</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>apoe_3/4</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apoe_3/4</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MH14BALCH</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MH14BALCH</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PTGENDER</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PTGENDER</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>apoe_2/4</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apoe_2/4</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>apoe_2/2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apoe_2/2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fnames    avg_fi  mappedGenes  pValue  beta  locations  snp  \\\n",
       "0        MH16BSMOK  0.170620          NaN     NaN   NaN        NaN  NaN   \n",
       "1   CLINICAL_LDL_C  0.167976          NaN     NaN   NaN        NaN  NaN   \n",
       "2              bmi  0.162582          NaN     NaN   NaN        NaN  NaN   \n",
       "3              AGE  0.144017          NaN     NaN   NaN        NaN  NaN   \n",
       "4         PTEDUCAT  0.142195          NaN     NaN   NaN        NaN  NaN   \n",
       "5         apoe_3/3  0.057643          NaN     NaN   NaN        NaN  NaN   \n",
       "6         apoe_2/3  0.047803          NaN     NaN   NaN        NaN  NaN   \n",
       "7         apoe_4/4  0.041209          NaN     NaN   NaN        NaN  NaN   \n",
       "8          GDTOTAL  0.024695          NaN     NaN   NaN        NaN  NaN   \n",
       "9         HMHYPERT  0.019840          NaN     NaN   NaN        NaN  NaN   \n",
       "10        apoe_3/4  0.016920          NaN     NaN   NaN        NaN  NaN   \n",
       "11       MH14BALCH  0.002413          NaN     NaN   NaN        NaN  NaN   \n",
       "12        PTGENDER  0.001657          NaN     NaN   NaN        NaN  NaN   \n",
       "13        apoe_2/4  0.000432          NaN     NaN   NaN        NaN  NaN   \n",
       "14        apoe_2/2  0.000000          NaN     NaN   NaN        NaN  NaN   \n",
       "\n",
       "            fnames    avg_fi  mappedGenes  pValue  beta  locations  snp  \n",
       "0        MH16BSMOK  0.170620          NaN     NaN   NaN        NaN  NaN  \n",
       "1   CLINICAL_LDL_C  0.167976          NaN     NaN   NaN        NaN  NaN  \n",
       "2              bmi  0.162582          NaN     NaN   NaN        NaN  NaN  \n",
       "3              AGE  0.144017          NaN     NaN   NaN        NaN  NaN  \n",
       "4         PTEDUCAT  0.142195          NaN     NaN   NaN        NaN  NaN  \n",
       "5         apoe_3/3  0.057643          NaN     NaN   NaN        NaN  NaN  \n",
       "6         apoe_2/3  0.047803          NaN     NaN   NaN        NaN  NaN  \n",
       "7         apoe_4/4  0.041209          NaN     NaN   NaN        NaN  NaN  \n",
       "8          GDTOTAL  0.024695          NaN     NaN   NaN        NaN  NaN  \n",
       "9         HMHYPERT  0.019840          NaN     NaN   NaN        NaN  NaN  \n",
       "10        apoe_3/4  0.016920          NaN     NaN   NaN        NaN  NaN  \n",
       "11       MH14BALCH  0.002413          NaN     NaN   NaN        NaN  NaN  \n",
       "12        PTGENDER  0.001657          NaN     NaN   NaN        NaN  NaN  \n",
       "13        apoe_2/4  0.000432          NaN     NaN   NaN        NaN  NaN  \n",
       "14        apoe_2/2  0.000000          NaN     NaN   NaN        NaN  NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "def summarize_stats(metrics1, metrics2): \n",
    "    path1 = os.path.join(metrics1, \"summary_stats/metrics.txt\")\n",
    "    path2 = os.path.join(metrics2, \"summary_stats/metrics.txt\")\n",
    "\n",
    "    df_metrics1 = pd.read_csv(path1)\n",
    "    df_metrics2 = pd.read_csv(path2)\n",
    "\n",
    "    merged_df = df_metrics1.merge(df_metrics2, on='Unnamed: 0').round(3)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def summarize_features(features1, features2):\n",
    "    path1 = os.path.join(features1, \"summary_stats/features.txt\")\n",
    "    path2 = os.path.join(features2, \"summary_stats/features.txt\")\n",
    "\n",
    "    df_features1 = pd.read_csv(path1)\n",
    "    df_features2 = pd.read_csv(path2)\n",
    "\n",
    "    df_features1 = df_features1.drop_duplicates(subset=['fnames'])\n",
    "    df_features2 = df_features2.drop_duplicates(subset=['fnames'])\n",
    "\n",
    "    merged_features = pd.concat([df_features1, df_features2], axis = 1)\n",
    "\n",
    "    return merged_features\n",
    "\n",
    "path0 = 'flaml_results'\n",
    "path1 = 'flaml_results'\n",
    "\n",
    "stats  = summarize_stats(path0, path1).T\n",
    "features = summarize_features(path0, path1)\n",
    "\n",
    "avg_auc1 = stats.iloc[1:6, 0].astype(float).mean()\n",
    "sd_auc1 = stats.iloc[1:6, 0].astype(float).std()\n",
    "avg_auc2 = stats.iloc[6:11, 0].astype(float).mean()\n",
    "sd_auc2 = stats.iloc[6:11, 0].astype(float).std()\n",
    "\n",
    "print(f\"Average AUROC for {path0}: {avg_auc1}, sd {sd_auc1}\")\n",
    "print(f\"Average AUROC for {path1}: {avg_auc2}, sd {sd_auc2}\")\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcd7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.674, 0.69,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123df103",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(stats.iloc[1:6].mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(stats.iloc[6:].mean()).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lowpyAD)",
   "language": "python",
   "name": "lowpyad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
