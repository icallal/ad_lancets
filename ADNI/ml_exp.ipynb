{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e65f197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>GDTOTAL</th>\n",
       "      <th>MH14BALCH</th>\n",
       "      <th>MH16BSMOK</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>HMHYPERT</th>\n",
       "      <th>DXAD</th>\n",
       "      <th>CLINICAL_LDL_C</th>\n",
       "      <th>bmi</th>\n",
       "      <th>apoe_2/2</th>\n",
       "      <th>apoe_2/3</th>\n",
       "      <th>apoe_2/4</th>\n",
       "      <th>apoe_3/3</th>\n",
       "      <th>apoe_3/4</th>\n",
       "      <th>apoe_4/4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.807508</td>\n",
       "      <td>27.305574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.193485</td>\n",
       "      <td>24.038731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.632129</td>\n",
       "      <td>27.169082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397560</td>\n",
       "      <td>26.998770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.347438</td>\n",
       "      <td>30.721924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>6992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.804546</td>\n",
       "      <td>28.161028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>7008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.804546</td>\n",
       "      <td>31.848550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>7012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.804546</td>\n",
       "      <td>36.603924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>7029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.804546</td>\n",
       "      <td>24.210783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>7068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.804546</td>\n",
       "      <td>23.751835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1878 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RID  GDTOTAL  MH14BALCH  MH16BSMOK   AGE  PTGENDER  PTEDUCAT  HMHYPERT  \\\n",
       "0        2      0.0        0.0        0.0  74.3       0.0      16.0       0.0   \n",
       "1        3      0.0        0.0        0.0  81.3       0.0      18.0       1.0   \n",
       "2        4      0.0        0.0        0.0  67.5       0.0      10.0       1.0   \n",
       "3        5      0.0        0.0        0.0  73.7       0.0      16.0       0.0   \n",
       "4        7      0.0        0.0        0.0  75.4       0.0      10.0       1.0   \n",
       "...    ...      ...        ...        ...   ...       ...       ...       ...   \n",
       "1873  6992      0.0        0.0        0.0  52.7       1.0      18.0       1.0   \n",
       "1874  7008      0.0        0.0        0.0  73.5       1.0      18.0       1.0   \n",
       "1875  7012      1.0        0.0        0.0  57.0       1.0      16.0       1.0   \n",
       "1876  7029      0.0        0.0        0.0  59.8       1.0      14.0       1.0   \n",
       "1877  7068      0.0        0.0        0.0  62.9       1.0      12.0       0.0   \n",
       "\n",
       "      DXAD  CLINICAL_LDL_C        bmi  apoe_2/2  apoe_2/3  apoe_2/4  apoe_3/3  \\\n",
       "0      0.0        1.807508  27.305574         0         0         0         1   \n",
       "1      1.0        3.193485  24.038731         0         0         0         0   \n",
       "2      0.0        2.632129  27.169082         0         0         0         1   \n",
       "3      0.0        1.397560  26.998770         0         0         0         1   \n",
       "4      1.0        3.347438  30.721924         0         0         0         0   \n",
       "...    ...             ...        ...       ...       ...       ...       ...   \n",
       "1873   0.0        2.804546  28.161028         0         0         0         1   \n",
       "1874   0.0        2.804546  31.848550         0         0         0         1   \n",
       "1875   0.0        2.804546  36.603924         0         0         1         0   \n",
       "1876   0.0        2.804546  24.210783         0         0         0         1   \n",
       "1877   0.0        2.804546  23.751835         0         0         0         1   \n",
       "\n",
       "      apoe_3/4  apoe_4/4  \n",
       "0            0         0  \n",
       "1            1         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            1         0  \n",
       "...        ...       ...  \n",
       "1873         0         0  \n",
       "1874         0         0  \n",
       "1875         0         0  \n",
       "1876         0         0  \n",
       "1877         0         0  \n",
       "\n",
       "[1878 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('ADNI_cleaned.parquet', engine='fastparquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--fold_index\", type=int, required=True)\n",
    "\n",
    "    parser.add_argument( # this modifies the field ids\n",
    "        \"--experiment\",\n",
    "        type=str,\n",
    "        help=\"\"\"Experiment name. Options:\n",
    "        'age' - only age\n",
    "        'apoe' - apoe only \n",
    "        'all' - everything\n",
    "        \"\"\",\n",
    "        required = False\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    fold_index = args.fold_index\n",
    "    experiment = args.experiment\n",
    "\n",
    "\n",
    "    return fold_index, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7ee4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def settings_automl(time_budget, metric):\n",
    "    \"\"\"\n",
    "    Generate settings for an AutoML classification task.\n",
    "    Parameters:\n",
    "    time_budget (int): The time budget for the AutoML process in seconds.\n",
    "    metric (str): The evaluation metric to be used (e.g., 'log_loss' 'accuracy', 'f1').\n",
    "    model (str): The model to be used in the AutoML process (e.g., 'lrl1').\n",
    "    region_index (int): The index of the region for logging purposes.\n",
    "    Returns:\n",
    "    dict: A dictionary containing the settings for the AutoML process.\n",
    "    \"\"\"\n",
    "    automl_settings = {\n",
    "            \"task\": \"classification\",\n",
    "            \"time_budget\": time_budget,\n",
    "            \"metric\": metric,\n",
    "            \"n_jobs\": -1,\n",
    "            \"eval_method\": \"cv\",\n",
    "            \"n_splits\": 5,\n",
    "            \"early_stop\": True,\n",
    "            \"log_training_metric\": True,\n",
    "            \"model_history\": True,\n",
    "            \"seed\": 1234321,\n",
    "            \"estimator_list\": ['lgbm'],\n",
    "    }\n",
    "\n",
    "    return automl_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6add9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_experiment_vars(df, experiment): \n",
    "    if experiment == 'age':\n",
    "        df = df[['AGE', 'DXAD']]\n",
    "        return df\n",
    "    elif experiment == 'apoe':\n",
    "        df = df[['apoe_2/2', 'apoe_2/3', 'apoe_2/4', 'apoe_3/3', 'apoe_3/4', 'apoe_4/4', 'DXAD']]\n",
    "        return df\n",
    "    elif experiment == 'all':\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9781b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from flaml import AutoML\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('../ukb')\n",
    "from doubleml_utils import subset_train_test\n",
    "\n",
    "def main(): \n",
    "    fold_index = 0\n",
    "    experiment = 'all'\n",
    "    # fold_index, experiment = parse_args()\n",
    "\n",
    "    df = pd.read_parquet('ADNI_cleaned.parquet', engine='fastparquet')\n",
    "    df = subset_experiment_vars(df, experiment)\n",
    "\n",
    "    X = df.drop(columns=['DXAD'])\n",
    "    y = df['DXAD']\n",
    "    \n",
    "    print('splitting')\n",
    "    \n",
    "    results_dir = f'./flaml_results/{fold_index}'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = subset_train_test(X, y, results_dir, fold_index)\n",
    "\n",
    "    print(f'training fold {fold_index} with experiment {experiment}')\n",
    "    automl = AutoML()\n",
    "    automl_settings = settings_automl(300, metric=\"log_loss\")\n",
    "    print(automl_settings)\n",
    "\n",
    "    logging.info(f\"Saving the model: {datetime.now().time()}\")\n",
    "\n",
    "    automl.fit(X_train, y_train, **automl_settings)\n",
    "\n",
    "    # save the model\n",
    "    best_model = automl.model.estimator\n",
    "\n",
    "    # Save just the best model\n",
    "    joblib.dump(best_model, f\"{results_dir}/flaml_best_model.joblib\")\n",
    "\n",
    "    logging.info(f\"Saving the predictions: {datetime.now().time()}\")\n",
    "    # save the test set predictions\n",
    "    y_pred = automl.predict_proba(X_test)\n",
    "    results = pd.DataFrame({\"y_test\": y_test, \"y_pred\": y_pred[:,1]})\n",
    "    results.to_parquet(\n",
    "        f\"{results_dir}/test_labels_predictions.parquet\", index=False\n",
    "    )\n",
    "\n",
    "    # save the train set predictions\n",
    "    y_pred = automl.predict_proba(X_train)\n",
    "    results = pd.DataFrame({\"y_train\": y_train, \"y_pred\": y_pred[:,1]})\n",
    "    results.to_parquet(\n",
    "        f\"{results_dir}/train_labels_predictions.parquet\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b910b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting\n",
      "training fold 0 with experiment all\n",
      "{'task': 'classification', 'time_budget': 300, 'metric': 'log_loss', 'n_jobs': -1, 'eval_method': 'cv', 'n_splits': 5, 'early_stop': True, 'log_training_metric': True, 'model_history': True, 'seed': 1234321, 'estimator_list': ['lgbm']}\n",
      "\u001b[33m[flaml.automl.logger: 09-04 11:48:13] {1644} WARNING - With `model_history` set to `True` by default, all intermediate models are retained in memory, which may significantly increase memory usage and slow down training. Consider setting `model_history=False` to optimize memory and accelerate the training process.\u001b[0m\n",
      "[flaml.automl.logger: 09-04 11:48:13] {1752} INFO - task = classification\n",
      "[flaml.automl.logger: 09-04 11:48:13] {1763} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 09-04 11:48:13] {1862} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl.logger: 09-04 11:48:13] {1979} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 0, current learner lgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 09-04 11:48:13] {2417} INFO - Estimated sufficient time budget=1220s. Estimated necessary time budget=1s.\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.2s,\testimator lgbm's best error=0.3147,\tbest estimator lgbm's best error=0.3147\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.2s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.3s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.3s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.2932,\tbest estimator lgbm's best error=0.2932\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.5s,\testimator lgbm's best error=0.2932,\tbest estimator lgbm's best error=0.2932\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.5s,\testimator lgbm's best error=0.2932,\tbest estimator lgbm's best error=0.2932\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.6s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2466} INFO -  at 0.6s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:13] {2282} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 0.7s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 0.7s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 0.8s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 0.8s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 0.9s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 0.9s,\testimator lgbm's best error=0.2899,\tbest estimator lgbm's best error=0.2899\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.0s,\testimator lgbm's best error=0.2890,\tbest estimator lgbm's best error=0.2890\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.3s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2466} INFO -  at 1.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:14] {2282} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 1.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 1.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 1.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 1.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 1.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 2.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 2.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 2.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2466} INFO -  at 2.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 09-04 11:48:15] {2282} INFO - iteration 35, current learner lgbm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(automl_settings)\n\u001b[1;32m     34\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mautoml_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[1;32m     39\u001b[0m best_model \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mestimator\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/automl.py:2007\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, mlflow_exp_name, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_estimator:\n\u001b[1;32m   2009\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit succeeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/automl.py:2572\u001b[0m, in \u001b[0;36mAutoML._search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlflow_integration\u001b[38;5;241m.\u001b[39mrecord_state(\n\u001b[1;32m   2567\u001b[0m             automl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2568\u001b[0m             search_state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[1;32m   2569\u001b[0m             estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   2570\u001b[0m         )\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_spark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m-> 2572\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_sequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_parallel()\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/automl.py:2382\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         search_state\u001b[38;5;241m.\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39msearcher\u001b[38;5;241m.\u001b[39mset_search_properties(\n\u001b[1;32m   2377\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2378\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2379\u001b[0m             metric_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[1;32m   2380\u001b[0m         )\n\u001b[1;32m   2381\u001b[0m start_run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 2382\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_budget_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_budget_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_spark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_cancel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_cancel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlflow_exp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mlflow_exp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoml_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass automl info to tune.run\u001b[39;49;00m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautolog_extra_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2394\u001b[0m time_used \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_run_time\n\u001b[1;32m   2395\u001b[0m better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/tune/tune.py:894\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, mlflow_exp_name, automl_info, extra_tag, cost_attr, cost_budget, **ray_args)\u001b[0m\n\u001b[1;32m    892\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[0;32m--> 894\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_to_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in tune: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_to_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/state.py:306\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[0;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    290\u001b[0m budget \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m )\n\u001b[1;32m    300\u001b[0m (\n\u001b[1;32m    301\u001b[0m     trained_estimator,\n\u001b[1;32m    302\u001b[0m     val_loss,\n\u001b[1;32m    303\u001b[0m     metric_for_logging,\n\u001b[1;32m    304\u001b[0m     _,\n\u001b[1;32m    305\u001b[0m     pred_time,\n\u001b[0;32m--> 306\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_X_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_y_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_time_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_time_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearner_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_score_agg_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_training_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_estimator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mretrain_final \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmodel_history:\n\u001b[1;32m    329\u001b[0m     trained_estimator\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/ml.py:382\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[0;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[1;32m    364\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[1;32m    365\u001b[0m         config_dic,\n\u001b[1;32m    366\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model_CV\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_val_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv_score_agg_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_training_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_training_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, TransformersEstimator):\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_val\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/task/generic_task.py:765\u001b[0m, in \u001b[0;36mGenericTask.evaluate_model_CV\u001b[0;34m(self, config, estimator, X_train_all, y_train_all, budget, kf, eval_metric, best_val_loss, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[1;32m    763\u001b[0m     groups_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X_train_all, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m--> 765\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_split\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    766\u001b[0m     X_val \u001b[38;5;241m=\u001b[39m X_train_split\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/pandas/core/indexing.py:1737\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   1735\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[0;32m-> 1737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/pandas/core/common.py:97\u001b[0m, in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     93\u001b[0m             name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_bool_indexer\u001b[39m(key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    Check whether `key` is a valid boolean indexer.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        and convert to an ndarray.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    126\u001b[0m         key, (ABCSeries, np\u001b[38;5;241m.\u001b[39mndarray, ABCIndex, ABCExtensionArray)\n\u001b[1;32m    127\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, ABCMultiIndex):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ac5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting\n",
      "{'task': 'classification', 'time_budget': 3600, 'metric': 'log_loss', 'n_jobs': -1, 'eval_method': 'cv', 'n_splits': 5, 'early_stop': True, 'log_training_metric': True, 'model_history': True, 'seed': 1234321, 'estimator_list': ['lgbm']}\n",
      "\u001b[33m[flaml.automl.logger: 08-30 19:03:32] {1644} WARNING - With `model_history` set to `True` by default, all intermediate models are retained in memory, which may significantly increase memory usage and slow down training. Consider setting `model_history=False` to optimize memory and accelerate the training process.\u001b[0m\n",
      "[flaml.automl.logger: 08-30 19:03:32] {1752} INFO - task = classification\n",
      "[flaml.automl.logger: 08-30 19:03:32] {1763} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-30 19:03:32] {1862} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl.logger: 08-30 19:03:32] {1979} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl.logger: 08-30 19:03:32] {2282} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2417} INFO - Estimated sufficient time budget=770s. Estimated necessary time budget=1s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.1s,\testimator lgbm's best error=0.3147,\tbest estimator lgbm's best error=0.3147\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.2s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.2s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.3s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.2955,\tbest estimator lgbm's best error=0.2955\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.5s,\testimator lgbm's best error=0.2932,\tbest estimator lgbm's best error=0.2932\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.6s,\testimator lgbm's best error=0.2932,\tbest estimator lgbm's best error=0.2932\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.6s,\testimator lgbm's best error=0.2932,\tbest estimator lgbm's best error=0.2932\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.7s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.8s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.8s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 0.9s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 1.0s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2466} INFO -  at 1.0s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:33] {2282} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.1s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.2s,\testimator lgbm's best error=0.2899,\tbest estimator lgbm's best error=0.2899\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.3s,\testimator lgbm's best error=0.2890,\tbest estimator lgbm's best error=0.2890\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 1.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2466} INFO -  at 2.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:34] {2282} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 2.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2466} INFO -  at 3.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:35] {2282} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.3s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 3.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 4.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2466} INFO -  at 4.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:36] {2282} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.3s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.3s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 4.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2466} INFO -  at 5.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:37] {2282} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 67, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.3s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 72, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 74, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 5.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2466} INFO -  at 6.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:38] {2282} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.3s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.4s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 82, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.5s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.6s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 84, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 85, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.7s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 86, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.8s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 6.9s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 7.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2466} INFO -  at 7.0s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:39] {2282} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.1s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 91, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.2s,\testimator lgbm's best error=0.2887,\tbest estimator lgbm's best error=0.2887\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.3s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.4s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.4s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.5s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.6s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.7s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.7s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.8s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 7.9s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 8.0s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2466} INFO -  at 8.1s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:40] {2282} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.1s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.2s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.3s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.4s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.5s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.5s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 109, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.6s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.7s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 8.8s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2466} INFO -  at 9.0s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:41] {2282} INFO - iteration 113, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.2s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.3s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.4s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.5s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.6s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.7s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.7s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.8s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 9.9s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 122, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2466} INFO -  at 10.0s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:42] {2282} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.1s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.1s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.2s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.3s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.4s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.4s,\testimator lgbm's best error=0.2880,\tbest estimator lgbm's best error=0.2880\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.5s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 130, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.6s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.7s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.8s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.8s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 10.9s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 11.0s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 136, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2466} INFO -  at 11.0s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:43] {2282} INFO - iteration 137, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.1s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.2s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.2s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.3s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.4s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 142, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.4s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.5s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 144, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.6s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 145, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.6s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.7s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.8s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.8s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 11.9s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 12.0s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2466} INFO -  at 12.1s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:44] {2282} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.1s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 153, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.2s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.3s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.3s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.4s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 157, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.5s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.5s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.6s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.7s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 161, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.7s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.8s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 163, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.9s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 164, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 12.9s,\testimator lgbm's best error=0.2878,\tbest estimator lgbm's best error=0.2878\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 165, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2466} INFO -  at 13.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:45] {2282} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 168, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 173, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 174, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 175, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 176, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 177, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 178, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 13.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 179, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2466} INFO -  at 14.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:46] {2282} INFO - iteration 180, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 181, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 182, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 186, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 187, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 188, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 191, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 14.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 193, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 15.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 194, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2466} INFO -  at 15.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:47] {2282} INFO - iteration 195, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 198, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 199, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 200, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 201, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 15.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 203, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2466} INFO -  at 16.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:48] {2282} INFO - iteration 204, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 205, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 206, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 207, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 208, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 209, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 210, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 211, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 212, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 213, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 214, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 215, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 216, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 16.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 217, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 17.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2466} INFO -  at 17.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:49] {2282} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 223, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 224, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 227, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 230, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 17.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 231, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 18.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 232, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2466} INFO -  at 18.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:50] {2282} INFO - iteration 233, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 234, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 235, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 236, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 237, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 238, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 239, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 240, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 241, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 243, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 244, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 245, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 18.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 246, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 19.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 247, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2466} INFO -  at 19.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:51] {2282} INFO - iteration 248, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 249, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 250, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 251, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 253, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 254, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 255, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 257, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 258, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 259, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 19.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 260, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 20.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 261, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2466} INFO -  at 20.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:52] {2282} INFO - iteration 262, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 263, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 264, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 265, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 266, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 267, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.4s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 268, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 269, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 270, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.6s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 271, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.7s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 272, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 273, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.8s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 274, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 20.9s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 275, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2466} INFO -  at 21.0s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:53] {2282} INFO - iteration 276, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2466} INFO -  at 21.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2282} INFO - iteration 277, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2466} INFO -  at 21.1s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2282} INFO - iteration 278, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2466} INFO -  at 21.2s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2282} INFO - iteration 279, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2466} INFO -  at 21.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2282} INFO - iteration 280, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2466} INFO -  at 21.3s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2282} INFO - iteration 281, current learner lgbm\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2466} INFO -  at 21.5s,\testimator lgbm's best error=0.2846,\tbest estimator lgbm's best error=0.2846\n",
      "[flaml.automl.logger: 08-30 19:03:54] {2282} INFO - iteration 282, current learner lgbm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(automl_settings)\n\u001b[1;32m     30\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mautoml_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m best_model \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mestimator\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/automl.py:2007\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, mlflow_exp_name, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_estimator:\n\u001b[1;32m   2009\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit succeeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/automl.py:2572\u001b[0m, in \u001b[0;36mAutoML._search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlflow_integration\u001b[38;5;241m.\u001b[39mrecord_state(\n\u001b[1;32m   2567\u001b[0m             automl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2568\u001b[0m             search_state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[1;32m   2569\u001b[0m             estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   2570\u001b[0m         )\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_spark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m-> 2572\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_sequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_parallel()\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/automl.py:2382\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         search_state\u001b[38;5;241m.\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39msearcher\u001b[38;5;241m.\u001b[39mset_search_properties(\n\u001b[1;32m   2377\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2378\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2379\u001b[0m             metric_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[1;32m   2380\u001b[0m         )\n\u001b[1;32m   2381\u001b[0m start_run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 2382\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_budget_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_budget_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_spark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_cancel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_cancel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlflow_exp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mlflow_exp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoml_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass automl info to tune.run\u001b[39;49;00m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautolog_extra_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2394\u001b[0m time_used \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_run_time\n\u001b[1;32m   2395\u001b[0m better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/tune/tune.py:894\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, mlflow_exp_name, automl_info, extra_tag, cost_attr, cost_budget, **ray_args)\u001b[0m\n\u001b[1;32m    892\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[0;32m--> 894\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_to_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in tune: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_to_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/state.py:306\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[0;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    290\u001b[0m budget \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m )\n\u001b[1;32m    300\u001b[0m (\n\u001b[1;32m    301\u001b[0m     trained_estimator,\n\u001b[1;32m    302\u001b[0m     val_loss,\n\u001b[1;32m    303\u001b[0m     metric_for_logging,\n\u001b[1;32m    304\u001b[0m     _,\n\u001b[1;32m    305\u001b[0m     pred_time,\n\u001b[0;32m--> 306\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_X_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_y_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_time_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_time_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearner_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_score_agg_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_training_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_estimator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mretrain_final \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmodel_history:\n\u001b[1;32m    329\u001b[0m     trained_estimator\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/ml.py:382\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[0;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[1;32m    364\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[1;32m    365\u001b[0m         config_dic,\n\u001b[1;32m    366\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model_CV\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_val_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv_score_agg_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_training_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_training_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, TransformersEstimator):\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_val\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/flaml/automl/task/generic_task.py:751\u001b[0m, in \u001b[0;36mGenericTask.evaluate_model_CV\u001b[0;34m(self, config, estimator, X_train_all, y_train_all, budget, kf, eval_metric, best_val_loss, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    749\u001b[0m         kf \u001b[38;5;241m=\u001b[39m kf\u001b[38;5;241m.\u001b[39msplit(X_train_split)\n\u001b[0;32m--> 751\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, val_index \u001b[38;5;129;01min\u001b[39;00m kf:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m    753\u001b[0m         train_index \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mpermutation(train_index)\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/model_selection/_split.py:1629\u001b[0m, in \u001b[0;36m_RepeatedSplits.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_repeats):\n\u001b[1;32m   1628\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv(random_state\u001b[38;5;241m=\u001b[39mrng, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcvargs)\n\u001b[0;32m-> 1629\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m   1630\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m train_index, test_index\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/model_selection/_split.py:411\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    405\u001b[0m         (\n\u001b[1;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    409\u001b[0m     )\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/model_selection/_split.py:142\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    140\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    141\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m    143\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m    144\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/model_selection/_split.py:838\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 838\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/model_selection/_split.py:778\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[0;32m--> 778\u001b[0m type_of_target_y \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/utils/multiclass.py:423\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(first_row_or_val):\n\u001b[1;32m    422\u001b[0m     first_row_or_val \u001b[38;5;241m=\u001b[39m first_row_or_val\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcached_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row_or_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/utils/_unique.py:105\u001b[0m, in \u001b[0;36mcached_unique\u001b[0;34m(xp, *ys)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_unique\u001b[39m(\u001b[38;5;241m*\u001b[39mys, xp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the unique values of ys.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Use the cached values from dtype.metadata if present.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        Unique values of ys.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_cached_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/utils/_unique.py:105\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_unique\u001b[39m(\u001b[38;5;241m*\u001b[39mys, xp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the unique values of ys.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Use the cached values from dtype.metadata if present.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        Unique values of ys.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_cached_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/utils/_unique.py:78\u001b[0m, in \u001b[0;36m_cached_unique\u001b[0;34m(y, xp)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     77\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/sklearn/utils/_array_api.py:416\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/numpy/lib/_arraysetops_impl.py:286\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    284\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lowpyAD/lib/python3.10/site-packages/numpy/lib/_arraysetops_impl.py:353\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[0m\n\u001b[1;32m    351\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    355\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    'AGE': 'curr_age',\n",
    "    'GDTOTAL': 'depression',\n",
    "    'MH14BALCH': 'alcohol_consumption', # not quite right - years of alcohol consumption\n",
    "    'apoe_3/3' : 'e3/e4',\n",
    "    'apoe_3/4' : 'e3/e4',\n",
    "    'apoe_4/4' : 'e4/e4',\n",
    "    'apoe_2/4' : 'e2/e4',\n",
    "    'apoe_2/3' : 'e2/e3',\n",
    "    'apoe_2/2' : 'e2/e2',\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lowpyAD)",
   "language": "python",
   "name": "lowpyad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
